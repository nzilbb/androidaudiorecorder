/**
 * This file was auto-generated by the Titanium Module SDK helper for Android
 * Appcelerator Titanium Mobile
 * Copyright (c) 2009-2010 by Appcelerator, Inc. All Rights Reserved.
 * Licensed under the terms of the Apache Public License
 * Please see the LICENSE included with this distribution for details.
 *
 */
package nz.ac.canterbury.nzilbb.androidaudiorecorder;

import org.appcelerator.kroll.KrollModule;
import org.appcelerator.kroll.annotations.Kroll;

import org.appcelerator.titanium.TiApplication;
import org.appcelerator.kroll.common.Log;
import org.appcelerator.kroll.common.TiConfig;

import android.media.AudioRecord;
import java.io.*;

import org.appcelerator.titanium.io.*;

@Kroll.module(name="Androidaudiorecorder", id="nz.ac.canterbury.nzilbb.androidaudiorecorder")
public class AndroidaudiorecorderModule extends KrollModule
{

	// Standard Debugging variables
	private static final String LCAT = "AndroidaudiorecorderModule";
	private static final boolean DBG = TiConfig.LOGD;

	// You can define constants with @Kroll.constant, for example:
	// @Kroll.constant public static final String EXTERNAL_NAME = value;
	
	// flag for current recording state
	private AudioRecord recorder = null;
	private Thread recordingThread = null;
	private File audioFile = null;
	private int bufferSizeInBytes;
	private int channelCount = 1;
	private int sampleRate = 44100;
	private int bitCount = 16;

	public AndroidaudiorecorderModule()
	{
		super();
	}

	@Kroll.onAppCreate
	public static void onAppCreate(TiApplication app)
	{
		Log.d(LCAT, "inside onAppCreate");
		// put module init code that needs to run when the application is created
	}

	// Methods
	/*
	@Kroll.method
	public String example()
	{
		Log.d(LCAT, "example called");
		return "hello world";
	}

	// Properties
	@Kroll.getProperty
	public String getExampleProp()
	{
		Log.d(LCAT, "get example property");
		return "hello world";
	}


	@Kroll.setProperty
	public void setExampleProp(String value) {
		Log.d(LCAT, "set example property: " + value);
	}
	*/

	/**
	 * Starts recording a file. Default settings are used:
	 * <ul>
	 *  <li>audioSource = android.media.MediaRecorder.AudioSource.MIC</li>
	 *  <li>sampleRateInHz = 44100</li>
	 *  <li>channelConfig = android.media.AudioFormat.CHANNEL_IN_MONO</li>
	 *  <li>audioFormat = android.media.AudioFormat.ENCODING_PCM_16BIT</li>
	 * </ul> 
	 */
	@Kroll.method
	public boolean start()
	{
		return start(-1,-1,-1,-1);
	}
	/**
	 * Starts recording a file.
	 * @param audioSource Use -1 for default android.media.MediaRecorder.AudioSource.MIC
	 * @param sampleRateInHz Use -1 for default 44100
	 * @param channelConfig Use -1 for default android.media.AudioFormat.CHANNEL_IN_MONO
	 * @param audioFormat Use -1 for default android.media.AudioFormat.ENCODING_PCM_16BIT 
	 */
	@Kroll.method
	public boolean start(int audioSource, int sampleRateInHz, int numberOfChannels, int audioFormat)
	{
		Log.d(LCAT, "AndroidaudiorecorderModule: start()");
		if (getRecording())
		{
			stop(); // stop recording
			if (audioFile != null) audioFile.delete(); // delete the file, it's location is unknown by the previous caller
		}
		audioFile = null;
		try
		{
			audioFile = File.createTempFile("AudioRecorder-", ".pcm", TiFileFactory.getDataDirectory(true));
			Log.e(LCAT, "AndroidaudiorecorderModule: file: " + audioFile.getPath());
		}
		catch (Exception x)
		{
			Log.e(LCAT, "AndroidaudiorecorderModule: failed to get file: " + x);
			return false;
		}
		
		if (audioSource < 0) audioSource = android.media.MediaRecorder.AudioSource.MIC;
		if (sampleRateInHz < 0) sampleRateInHz = 44100;
		if (audioFormat < 0) audioFormat = android.media.AudioFormat.ENCODING_PCM_16BIT;
		if (numberOfChannels < 0) numberOfChannels = 1;
		int channelConfig = numberOfChannels==1?android.media.AudioFormat.CHANNEL_IN_MONO:android.media.AudioFormat.CHANNEL_IN_STEREO;
		bufferSizeInBytes = AudioRecord.getMinBufferSize(sampleRateInHz, channelConfig, audioFormat);
		if (bufferSizeInBytes == android.media.AudioRecord.ERROR_BAD_VALUE)
		{
			// one of the parameters is not supported - use values that are guaranteed to work
			if (sampleRateInHz != 4410) sampleRateInHz = 44100;
			bufferSizeInBytes = AudioRecord.getMinBufferSize(sampleRateInHz, channelConfig, audioFormat);
			if (bufferSizeInBytes == android.media.AudioRecord.ERROR_BAD_VALUE)
			{
				// one of the parameters is not supported - try mono (supported on all platforms)
				Log.e(LCAT, "AndroidaudiorecorderModule: invalid config - trying mono");
				channelConfig = android.media.AudioFormat.CHANNEL_IN_MONO;
				bufferSizeInBytes = AudioRecord.getMinBufferSize(sampleRateInHz, channelConfig, audioFormat);
				if (bufferSizeInBytes == android.media.AudioRecord.ERROR_BAD_VALUE)
				{
					// one of the parameters is not supported - try 16 bit PCM
					Log.e(LCAT, "AndroidaudiorecorderModule: invalid config - trying 16 bit PCM");
					audioFormat = android.media.AudioFormat.ENCODING_PCM_16BIT;
					bufferSizeInBytes = AudioRecord.getMinBufferSize(sampleRateInHz, channelConfig, audioFormat);
					if (bufferSizeInBytes == android.media.AudioRecord.ERROR_BAD_VALUE)
					{
						// one of the parameters is not supported - use values that are guaranteed to work
						Log.e(LCAT, "AndroidaudiorecorderModule: invalid config - trying 44,100kHz");
						sampleRateInHz = 44100;
						bufferSizeInBytes = AudioRecord.getMinBufferSize(sampleRateInHz, channelConfig, audioFormat);
						if (bufferSizeInBytes == android.media.AudioRecord.ERROR_BAD_VALUE)
						{
							Log.e(LCAT, "AndroidaudiorecorderModule: failed to getMinBufferSize()");
							bufferSizeInBytes = 10000; // this will probably fail below
						}
					}
				}
			}
		}
		//bufferSizeInBytes *= 1024;
		try
		{
			if (recorder == null)
			{
				recorder = new AudioRecord(audioSource, sampleRateInHz, channelConfig, audioFormat, bufferSizeInBytes);
			}
			channelCount = recorder.getChannelCount();
			sampleRate = recorder.getSampleRate();
			bitCount = recorder.getAudioFormat()==android.media.AudioFormat.ENCODING_PCM_8BIT?8:16;
			recorder.startRecording();
			recordingThread = new Thread(new Runnable() {
		        public void run() {
		            writeAudioDataToFile();
		        }
		    }, "AudioRecorder Thread");
		    recordingThread.start();
		}
		catch (IllegalArgumentException x)
		{
			Log.e(LCAT, "AndroidaudiorecorderModule: failed to create AudioRecord instance: " + x);
			return false;
		}
		return true;
	}

	private void writeAudioDataToFile() 
	{
		try
		{
			Log.d(LCAT, "writeAudioDataToFile");
			if (audioFile != null && recorder != null && recordingThread != null)
			{
				byte data[] = new byte[bufferSizeInBytes];
	
				FileOutputStream os = null;
				try 
				{
					os = new FileOutputStream(audioFile.getPath());
					Log.d(LCAT, "writeAudioDataToFile opened " + audioFile.getPath());
				} 
				catch (FileNotFoundException e) 
				{
					e.printStackTrace();
				}
	
				while (audioFile != null && recorder != null && recordingThread != null) 
				{
					int iRead = recorder.read(data, 0, bufferSizeInBytes);
					Log.d(LCAT, "writeAudioDataToFile read " + iRead);
					if (iRead > 0)
					{
						try 
						{
							os.write(data, 0, iRead);
						} 
						catch (IOException e) 
						{
							e.printStackTrace();
						}
					}
				}
				Log.d(LCAT, "writeAudioDataToFile closing");
				try 
				{
					os.close();
				} 
				catch (IOException e) 
				{
					e.printStackTrace();
				}
			} // everything still ok to record
		}
		finally
		{
			// we're finished
			recordingThread = null;
			Log.e(LCAT, "writeAudioDataToFile finished");
		}
	}


	/**
	 * Stops the current recording session.
	 * @return The path to the resulting audio file, or null if the recorder wasn't currently recording.
	 */
	@Kroll.method
	public String stop()
	{
		Log.e(LCAT, "AndroidaudiorecorderModule: stop()");
		if (null != recorder) 
		{
	        recorder.stop();
	        //recorder.release();
	        //recorder = null;
	        recordingThread = null;
	        while (recordingThread != null)
	        { // wait for thread to finish
	        	try { Thread.sleep(100); } catch (Exception x) {}
	        }
	        Log.e(LCAT, "File: " + audioFile.getPath() + " " + audioFile.exists());
	        audioFile = addWavHeader(audioFile);
	        Log.e(LCAT, "File: " + audioFile.getPath() + " " + audioFile.exists());
			return audioFile.getName();
	    }
		else
		{
			return null; // wasn't recording
		}
	}
	
	private File addWavHeader(File fPCM)
	{
		File wav = new File(fPCM.getParentFile(), fPCM.getName().replaceAll("\\.pcm$", "") + ".wav");
	    try {
	        long mySubChunk1Size = 16;
	        int myBitsPerSample= bitCount;
	        int myFormat = 1;
	        long myChannels = channelCount;
	        long mySampleRate = sampleRate;
	        long myByteRate = mySampleRate * myChannels * myBitsPerSample/8;
	        int myBlockAlign = (int) (myChannels * myBitsPerSample/8);

	        long myDataSize = fPCM.length();
	        long myChunk2Size =  myDataSize * myChannels * myBitsPerSample/8;
	        long myChunkSize = 36 + myChunk2Size;

	        OutputStream os = new FileOutputStream(wav);
	        BufferedOutputStream bos = new BufferedOutputStream(os);
	        DataOutputStream outFile = new DataOutputStream(bos);

	        outFile.writeBytes("RIFF");                                 // 00 - RIFF
	        outFile.write(intToByteArray((int)myChunkSize), 0, 4);      // 04 - how big is the rest of this file?
	        outFile.writeBytes("WAVE");                                 // 08 - WAVE
	        outFile.writeBytes("fmt ");                                 // 12 - fmt 
	        outFile.write(intToByteArray((int)mySubChunk1Size), 0, 4);  // 16 - size of this chunk
	        outFile.write(shortToByteArray((short)myFormat), 0, 2);     // 20 - what is the audio format? 1 for PCM = Pulse Code Modulation
	        outFile.write(shortToByteArray((short)myChannels), 0, 2);   // 22 - mono or stereo? 1 or 2?  (or 5 or ???)
	        outFile.write(intToByteArray((int)mySampleRate), 0, 4);     // 24 - samples per second (numbers per second)
	        outFile.write(intToByteArray((int)myByteRate), 0, 4);       // 28 - bytes per second
	        outFile.write(shortToByteArray((short)myBlockAlign), 0, 2); // 32 - # of bytes in one sample, for all channels
	        outFile.write(shortToByteArray((short)myBitsPerSample), 0, 2);  // 34 - how many bits in a sample(number)?  usually 16 or 24
	        outFile.writeBytes("data");                                 // 36 - data
	        outFile.write(intToByteArray((int)myDataSize), 0, 4);       // 40 - how big is this data chunk
	        //outFile.write(clipData);                                    // 44 - the actual data itself - just a long string of numbers
	        FileInputStream pcmIn = new FileInputStream(fPCM);
	        byte buffer[] = new byte[1024];
	        int iBytesRead = pcmIn.read(buffer);
	        while (iBytesRead > 0)
	        {
	        	outFile.write(buffer, 0, iBytesRead);
	        	iBytesRead = pcmIn.read(buffer);
	        } // next chunk
	        pcmIn.close();

	        outFile.flush();
	        outFile.close();

	    } catch (IOException e) {
	    	Log.e(LCAT, "error writing WAV data: " + e);
	        e.printStackTrace();
	    }
		fPCM.delete();
		return wav;
	}
	
	/**
	 * Determines whether the module is currently recording audio or not.
	 * @return true if the module is recording, false otherwise.
	 */
	@Kroll.method
	public boolean getRecording()
	{
		return /*recorder*/recordingThread != null;
	}


	private static byte[] intToByteArray(int i)
	    {
	        byte[] b = new byte[4];
	        b[0] = (byte) (i & 0x00FF);
	        b[1] = (byte) ((i >> 8) & 0x000000FF);
	        b[2] = (byte) ((i >> 16) & 0x000000FF);
	        b[3] = (byte) ((i >> 24) & 0x000000FF);
	        return b;
	    }

	    // convert a short to a byte array
	    public static byte[] shortToByteArray(short data)
	    {
	        /*
	         * NB have also tried:
	         * return new byte[]{(byte)(data & 0xff),(byte)((data >> 8) & 0xff)};
	         * 
	         */

	        return new byte[]{(byte)(data & 0xff),(byte)((data >>> 8) & 0xff)};
	    }
}

